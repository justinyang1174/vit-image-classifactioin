{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d41d324-9c33-4021-8f69-5e1c4d4f6d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1/30 - Training: 100%|███████████████████████████████████████████████████████████| 81/81 [05:05<00:00,  3.77s/it]\n",
      "Epoch 1/30 - Validation: 100%|█████████████████████████████████████████████████████████| 19/19 [00:16<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model saved with validation accuracy: 0.7567\n",
      "Epoch : 1 - train_loss : 24.5352 - train_acc: 0.6356 - val_loss : 0.5583 - val_acc: 0.7567\n",
      "Validation Metrics: Precision: 0.7567, Recall: 0.7567, F1-Score: 0.7567\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 - Training: 100%|███████████████████████████████████████████████████████████| 81/81 [05:01<00:00,  3.72s/it]\n",
      "Epoch 2/30 - Validation: 100%|█████████████████████████████████████████████████████████| 19/19 [00:16<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model saved with validation accuracy: 0.8100\n",
      "Epoch : 2 - train_loss : 24.0880 - train_acc: 0.8424 - val_loss : 0.4640 - val_acc: 0.8100\n",
      "Validation Metrics: Precision: 0.8204, Recall: 0.8100, F1-Score: 0.8084\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 - Training:  90%|█████████████████████████████████████████████████████▏     | 73/81 [04:39<00:30,  3.83s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2884\\127366300.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2884\\127366300.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlasso_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCONFIG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lasso_lambda'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[1;32m--> 488\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    confusion_matrix, \n",
    "    classification_report\n",
    ")\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'seed': 42,\n",
    "    'model_name': \"google/vit-base-patch16-224\",\n",
    "    'batch_size': 16,\n",
    "    'num_epochs': 30,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-2,\n",
    "    'lasso_lambda': 1e-3,\n",
    "    'train_dir': '/Users/user/Desktop/project/image/train2',\n",
    "    'val_dir': '/Users/user/Desktop/project/image/vaildation2',\n",
    "    'checkpoint_path': 'vit.pth'\n",
    "}\n",
    "\n",
    "def main():\n",
    "    # Set random seed\n",
    "    set_seed(CONFIG['seed'])\n",
    "\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Load pre-trained ViT model and image processor\n",
    "    model = ViTForImageClassification.from_pretrained(\n",
    "        CONFIG['model_name'], \n",
    "        num_labels=2, \n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "    image_processor = ViTImageProcessor.from_pretrained(CONFIG['model_name'])\n",
    "\n",
    "    # Custom classifier head\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(model.config.hidden_size, 1024),\n",
    "        nn.BatchNorm1d(1024),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(1024, 512),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(512, 2)\n",
    "    )\n",
    "\n",
    "    # Load pre-trained weights if exists\n",
    "    start_epoch = 0\n",
    "    if os.path.exists(CONFIG['checkpoint_path']):\n",
    "        try:\n",
    "            checkpoint = torch.load(CONFIG['checkpoint_path'], map_location=device)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            start_epoch = checkpoint['epoch'] + 1\n",
    "            print(f\"Loaded pre-trained model from {CONFIG['checkpoint_path']} at epoch {start_epoch}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading checkpoint: {e}\")\n",
    "\n",
    "    # Move model to device\n",
    "    model.to(device)\n",
    "\n",
    "    # Define data transforms\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Load datasets\n",
    "    train_dataset = ImageFolder(CONFIG['train_dir'], transform=train_transform)\n",
    "    val_dataset = ImageFolder(CONFIG['val_dir'], transform=val_transform)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=CONFIG['batch_size'], \n",
    "        shuffle=True, \n",
    "        num_workers=0\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=CONFIG['batch_size'], \n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    # Custom loss function with Lasso regularization\n",
    "    def lasso_loss(model, criterion, outputs, labels, lasso_lambda):\n",
    "        # Standard cross-entropy loss\n",
    "        standard_loss = criterion(outputs.logits, labels)\n",
    "        \n",
    "        # Lasso regularization (L1 penalty)\n",
    "        l1_penalty = sum(p.abs().sum() for p in model.classifier.parameters() if p.requires_grad)\n",
    "        \n",
    "        # Combined loss\n",
    "        return standard_loss + lasso_lambda * l1_penalty\n",
    "\n",
    "    # Optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=CONFIG['learning_rate'], \n",
    "        weight_decay=CONFIG['weight_decay']\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, \n",
    "        max_lr=CONFIG['learning_rate'], \n",
    "        epochs=CONFIG['num_epochs'], \n",
    "        steps_per_epoch=len(train_loader)\n",
    "    )\n",
    "\n",
    "    # Training metrics storage\n",
    "    train_losses, train_accuracies = [], []\n",
    "    val_losses, val_accuracies = [], []\n",
    "    val_precisions, val_recalls, val_f1_scores = [], [], []\n",
    "\n",
    "    # Best model tracking\n",
    "    best_val_accuracy = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(start_epoch, CONFIG['num_epochs']):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        epoch_loss, epoch_accuracy = 0, 0\n",
    "\n",
    "        for data, label in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{CONFIG['num_epochs']} - Training\"):\n",
    "            data, label = data.to(device), label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data, labels=label)\n",
    "            \n",
    "            # Custom loss with Lasso regularization\n",
    "            loss = lasso_loss(model, criterion, outputs, label, CONFIG['lasso_lambda'])\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            acc = (outputs.logits.argmax(dim=1) == label).float().mean()\n",
    "            epoch_accuracy += acc.item() / len(train_loader)\n",
    "            epoch_loss += loss.item() / len(train_loader)\n",
    "\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_accuracy)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        all_preds, all_labels, all_probs = [], [], []\n",
    "        epoch_val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, label in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{CONFIG['num_epochs']} - Validation\"):\n",
    "                data, label = data.to(device), label.to(device)\n",
    "\n",
    "                outputs = model(data, labels=label)\n",
    "                val_loss = criterion(outputs.logits, label)\n",
    "\n",
    "                probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "                preds = torch.argmax(probs, dim=1)\n",
    "                \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(label.cpu().numpy())\n",
    "                all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "\n",
    "                epoch_val_loss += val_loss.item() / len(val_loader)\n",
    "\n",
    "        # Calculate validation metrics\n",
    "        val_accuracy = accuracy_score(all_labels, all_preds)\n",
    "        val_precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "        val_recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "        val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "        # Save the best model\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_accuracy': val_accuracy,\n",
    "            }, CONFIG['checkpoint_path'])\n",
    "            print(f\"\\nBest model saved with validation accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "        # Store validation metrics\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_precisions.append(val_precision)\n",
    "        val_recalls.append(val_recall)\n",
    "        val_f1_scores.append(val_f1)\n",
    "\n",
    "        # Print epoch summary\n",
    "        print(\n",
    "            f\"Epoch : {epoch+1} - \"\n",
    "            f\"train_loss : {epoch_loss:.4f} - train_acc: {epoch_accuracy:.4f} - \"\n",
    "            f\"val_loss : {epoch_val_loss:.4f} - val_acc: {val_accuracy:.4f}\\n\"\n",
    "            f\"Validation Metrics: \"\n",
    "            f\"Precision: {val_precision:.4f}, \"\n",
    "            f\"Recall: {val_recall:.4f}, \"\n",
    "            f\"F1-Score: {val_f1:.4f}\\n\"\n",
    "        )\n",
    "\n",
    "    # Optional: Plot training and validation metrics\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(131)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.title('Loss Curves')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.plot(train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(val_accuracies, label='Val Accuracy')\n",
    "    plt.title('Accuracy Curves')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.plot(val_precisions, label='Precision')\n",
    "    plt.plot(val_recalls, label='Recall')\n",
    "    plt.plot(val_f1_scores, label='F1-Score')\n",
    "    plt.title('Validation Metrics')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d3d3a-dd6f-4825-9fba-a0f0e46e5bca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
