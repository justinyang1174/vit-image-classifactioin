{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a953103a-8fcf-475d-9b36-20c1cb5c33e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from transformers import DeiTForImageClassification\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'seed': 42,\n",
    "    'model_name': \"facebook/deit-base-patch16-224\",  # Changed to DeiT model\n",
    "    'batch_size': 16,\n",
    "    'num_epochs': 300,\n",
    "    'learning_rate': 2e-4,  # Lowered learning rate for fine-tuning\n",
    "    'weight_decay': 1e-4,\n",
    "    'train_dir': '/Users/user/Desktop/project/image/train2',\n",
    "    'val_dir': '/Users/user/Desktop/project/image/vaildation2',  # Update these paths to your actual paths\n",
    "    'pretrained_weights': 'best_model_0114.pth',\n",
    "    'new_checkpoint_path': 'deit_model_checkpoint.pth',  # Updated filename\n",
    "    'accumulation_steps': 2\n",
    "}\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def load_pretrained_model(model, weights_path, device):\n",
    "    \"\"\"Load pretrained weights into model\"\"\"\n",
    "    if not os.path.exists(weights_path):\n",
    "        print(f\"Warning: Weights file {weights_path} not found!\")\n",
    "        return model, 0\n",
    "        \n",
    "    try:\n",
    "        checkpoint = torch.load(weights_path, map_location=device)\n",
    "        \n",
    "        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            start_epoch = 0\n",
    "            print(\"Loaded checkpoint and starting from epoch 1\")\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)\n",
    "            start_epoch = 0\n",
    "            print(\"Loaded model weights\")\n",
    "            \n",
    "        print(f\"Successfully loaded weights from {weights_path}\")\n",
    "        return model, start_epoch\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading weights: {e}\")\n",
    "        print(\"Starting with fresh model\")\n",
    "        return model, 0\n",
    "\n",
    "def plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies, save_dir='./plots'):\n",
    "    \"\"\"Plot training and validation loss/accuracy curves\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Plot Loss Curves\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Loss Curves')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(save_dir, 'deit_loss_curves.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot Accuracy Curves\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "    plt.title('Accuracy Curves')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(save_dir, 'deit_accuracy_curves.png'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, save_dir='./plots'):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(os.path.join(save_dir, 'deit_confusion_matrix.png'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_roc_curve(y_true, y_prob, save_dir='./plots'):\n",
    "    \"\"\"Plot ROC curve\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(save_dir, 'deit_roc_curve.png'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_performance_metrics(precisions, recalls, f1_scores, save_dir='./plots'):\n",
    "    \"\"\"Plot performance metrics over epochs\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    epochs = range(1, len(precisions) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(epochs, precisions, 'b-', label='Precision')\n",
    "    plt.plot(epochs, recalls, 'r-', label='Recall')\n",
    "    plt.plot(epochs, f1_scores, 'g-', label='F1-Score')\n",
    "    plt.title('Performance Metrics Over Time')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(save_dir, 'deit_performance_metrics.png'))\n",
    "    plt.close()\n",
    "\n",
    "def validate_with_predictions(model, val_loader, criterion, device):\n",
    "    \"\"\"Validation function that returns predictions and probabilities\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, targets in tqdm(val_loader, desc=\"Validating\"):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs.logits, targets)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            probabilities = torch.softmax(outputs.logits, dim=1)\n",
    "            _, predicted = outputs.logits.max(1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities[:, 1].cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    precision = precision_score(all_targets, all_predictions, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_targets, all_predictions, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_targets, all_predictions, average='weighted', zero_division=0)\n",
    "    \n",
    "    return (total_loss / len(val_loader), accuracy, precision, recall, f1, \n",
    "            all_targets, all_predictions, all_probabilities)\n",
    "\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    \"\"\"Performs mixup on the input data and returns mixed inputs, pairs of targets, and lambda\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    \"\"\"Computes the mixup loss\"\"\"\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "def train_one_epoch(model, train_loader, optimizer, criterion, device, scheduler=None, accumulation_steps=1, clip_value=1.0):\n",
    "    \"\"\"Enhanced training function with mixup and gradient clipping\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Apply mixup\n",
    "        inputs, targets_a, targets_b, lam = mixup_data(inputs, targets)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs).logits\n",
    "        loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "        \n",
    "        # Scale loss for gradient accumulation\n",
    "        loss = loss / accumulation_steps\n",
    "        loss.backward()\n",
    "        \n",
    "        if (batch_idx + 1) % accumulation_steps == 0:\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item() * accumulation_steps\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += (lam * predicted.eq(targets_a).sum().float() + \n",
    "                   (1 - lam) * predicted.eq(targets_b).sum().float())\n",
    "    \n",
    "    acc = (correct / total).cpu().item()  # Move to CPU and get item\n",
    "    return total_loss / len(train_loader), acc\n",
    "\n",
    "\n",
    "def main():\n",
    "    set_seed(CONFIG['seed'])\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize DeiT model instead of ViT\n",
    "        print(\"Initializing Data-efficient Vision Transformer (DeiT) model...\")\n",
    "        model = DeiTForImageClassification.from_pretrained(\n",
    "            CONFIG['model_name'],\n",
    "            num_labels=2,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        \n",
    "        # Enhanced classifier head with progressive dropout\n",
    "        model.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(model.config.hidden_size, 256),\n",
    "            torch.nn.BatchNorm1d(256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(256, 2)\n",
    "        )\n",
    "        \n",
    "        # Note: If you're trying to load weights from a standard ViT model, they might not be compatible\n",
    "        # with DeiT due to architecture differences. You might need to start with fresh weights.\n",
    "        try:\n",
    "            model, start_epoch = load_pretrained_model(model, CONFIG['pretrained_weights'], device)\n",
    "        except:\n",
    "            print(\"Could not load pretrained weights - architecture mismatch. Starting with fresh model.\")\n",
    "            start_epoch = 0\n",
    "            \n",
    "        model.to(device)\n",
    "        \n",
    "        # DeiT-specific data transforms\n",
    "        # DeiT uses stronger augmentation than standard ViT\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.RandomRotation(45),  # Stronger rotation\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),  # Stronger color jitter\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.8, 1.2)),  # Stronger affine\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomErasing(p=0.3),  # Increased erasing probability\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # Dataset loading\n",
    "        print(\"Loading datasets...\")\n",
    "        train_dataset = ImageFolder(CONFIG['train_dir'], transform=train_transform)\n",
    "        val_dataset = ImageFolder(CONFIG['val_dir'], transform=val_transform)\n",
    "        \n",
    "        print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "        print(f\"Number of validation samples: {len(val_dataset)}\")\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=CONFIG['batch_size'], \n",
    "            shuffle=True, \n",
    "            num_workers=0\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=CONFIG['batch_size'], \n",
    "            shuffle=False, \n",
    "            num_workers=0\n",
    "        )\n",
    "        \n",
    "        # Enhanced optimizer settings for DeiT\n",
    "        # DeiT typically uses a different learning rate schedule\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=CONFIG['learning_rate'],\n",
    "            weight_decay=0.05,  # Increased weight decay for DeiT\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-8\n",
    "        )\n",
    "        \n",
    "        # Cosine learning rate scheduler with warmup - better for DeiT\n",
    "        num_training_steps = len(train_loader) * CONFIG['num_epochs']\n",
    "        num_warmup_steps = int(0.1 * num_training_steps)  # 10% warmup\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer,\n",
    "            T_0=10,  # Restart every 10 epochs\n",
    "            T_mult=1,\n",
    "            eta_min=1e-6\n",
    "        )\n",
    "        \n",
    "        class_weights = torch.tensor([1.0, 0.42]).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        \n",
    "        # Training metrics storage\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        f1_scores = []\n",
    "        best_val_accuracy = 0\n",
    "        \n",
    "        print(\"Starting training with Data-efficient Vision Transformer (DeiT)...\")\n",
    "        for epoch in range(start_epoch, CONFIG['num_epochs']):\n",
    "            print(f\"\\nEpoch {epoch + 1}/{CONFIG['num_epochs']}\")\n",
    "            \n",
    "            # Train\n",
    "            train_loss, train_acc = train_one_epoch(\n",
    "                model, train_loader, optimizer, criterion, device,\n",
    "                scheduler=None,  # We'll step the scheduler after each epoch\n",
    "                accumulation_steps=CONFIG['accumulation_steps'],\n",
    "                clip_value=1.0\n",
    "            )\n",
    "            \n",
    "            # Step the scheduler after each epoch\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, val_acc, precision, recall, f1, targets, predictions, probabilities = validate_with_predictions(\n",
    "                model, val_loader, criterion, device\n",
    "            )\n",
    "            \n",
    "            # Store metrics (ensure they're CPU values)\n",
    "            train_losses.append(float(train_loss))\n",
    "            val_losses.append(float(val_loss))\n",
    "            train_accuracies.append(float(train_acc))\n",
    "            val_accuracies.append(float(val_acc))\n",
    "            precisions.append(float(precision))\n",
    "            recalls.append(float(recall))\n",
    "            f1_scores.append(float(f1))\n",
    "            \n",
    "            print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%\")\n",
    "            print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc*100:.2f}%\")\n",
    "            print(f\"Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\")\n",
    "            print(f\"Current learning rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "            \n",
    "            # Save best model\n",
    "            if val_acc > best_val_accuracy:\n",
    "                best_val_accuracy = val_acc\n",
    "                print(f\"Saving best model with validation accuracy: {val_acc*100:.2f}%\")\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'val_accuracy': val_acc,\n",
    "                }, CONFIG['new_checkpoint_path'])\n",
    "        \n",
    "        # Plot visualizations\n",
    "        print(\"\\nGenerating visualization plots...\")\n",
    "        plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies)\n",
    "        plot_confusion_matrix(targets, predictions)\n",
    "        plot_roc_curve(targets, probabilities)\n",
    "        plot_performance_metrics(precisions, recalls, f1_scores)\n",
    "        print(\"All plots have been saved in the 'plots' directory\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
